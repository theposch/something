Extensibility in Orders Platform
Steve Chen


Why have extensions?


A platform has two essential, interrelated roles:
1. Encapsulating common functionalities to make possible “build it once, use everywhere”, 
2. Enabling new functionalities to be built to meet customer needs


Because a platform team cannot anticipate all possible needs, and since many of the needs are specific to particular clients rather than commonly shared, sooner or later, in the life of every platform, the extensibility question inevitably comes up. One way to enable new functionality is to enable software to be built on top of it, but how much should the platform enable software to be built into it?


Related, due to many reasons (not the least of which is that the platform team is downstream from all the clients building things on top of it), the platform team invariably finds themselves to be the bottleneck, and thus discussions come up on how to alleviate the pressure[a][b][c][d][e][f][g][h][i][j][k].


Indeed, we find ourselves in that very situation. I am writing this doc to outline a strawman framework for thinking about extensibility,[l] and get us aligned on a strategy to support it.


To be clear, this is a discussion about how; to me, it is not an option to not support it. Furthermore, supporting it requires a significant investment, and one that is essential for us in 2022.


At a fundamental level, the Orders Core API encapsulates two valuable things:
1. A shared data model
2. A shared set of systems, pipelines, and workflows that process and propagates the data, e.g. to reporting backends


The sharing of the data and logic is of course one of the key values of the platform - it is how we achieve the scale of building it once for all clients, instead of each client building everything on their own.
Extensible Data


Not all transaction related data fits into a shared data model, though; there will inevitably be use cases for some data that are specific to some clients but not others. One option is to ask the clients to store that in a separate data model altogether, and manage that on their own. This is similar in nature to teams building their own primitives.


However, this is where the “shared set of systems / pipelines” comes in - for relatively simple pieces of data, it would be far easier for everyone involved to add it to the Orders object and then “ride the Orders rail” through the shared set of systems / pipelines. This is likely a key motivation for Custom Attributes.


Where to draw the lines is not inherently obvious, though. To guide making these decisions consistently, we need clear principles[m][n] for:


* When should something be modeled in the shared data model vs. a data extension? If only one client needs, the answer seems clear. But what about when there are two clients?[o][p][q][r][s][t][u]
   * This also determines what we need to support in terms of visibility of the data extensions - should clients have access to each other’s data extensions?
   * Should the Orders shared system / pipelines understand what the data contains?
* When is it appropriate for clients to store their data as an Orders data extension vs. building their own primitive?[v][w][x][y][z][aa]


A related question: when do we get involved in the data extension process? After all, that is one potential way for us to discover new potential features for the shared data model.
Extensible Logic


While some client needs can be met by solely extending data and having the data pass through the entire end-to-end system untouched, other times the needs can only be met by customizing the data processing. This is where code extensions come in. For example, one pattern that may come up is the need to transform the data extension for reporting purposes[ab].


A related job-to-be-done is when clients need to customize the logic on the shared data model. As a simplistic (contrived) example, instead of doing A followed by B[ac], the client may need it to be the reverse. Supporting this requires representing the logic themselves into composable blocks, and in practice it can be challenging to find the right level of abstraction.[ad][ae][af]


In general, code extensions could bring much more complexity[ag][ah][ai][aj][ak][al] than data extensions, and make the system more difficult to understand and reason about[am][an]. It is therefore both critical but also must be done judiciously. Because there are practically infinite ways that clients may want to customize code logic, we need to clearly understand the use cases, and choose to support the ones with the highest ROI.
Extensible Clients / UI


Similar needs for data and logic extensions exist at all layers. For example, when clients add data extensions, they would likely want that represented in client abstractions in the SDK. Separately, they may also want custom abstractions in the SDK itself to project/group lower-level Orders data fields to a convenient concept. There are good examples of demands for customizations of orchestration logic and UI flows in Checkout.


Layers of Extensions


Because clients may want / need to extend the platform at multiple layers of the stack, our extension strategy should be coherent end-to-end, rather than each layer having its own siloed version. 


That said, it is not necessarily the case for all layers of the stack to be equally extensible. As we go from the lower-level primitives to higher-level abstractions, it should become less extensible and flexible.[ao] The higher-level abstractions are built to be our opinionated implementation of a key subset of use cases - if the clients need more flexibility, they can build it using lower-level primitives[ap][aq].


Finally, our goal is to enable clients to help our sellers, so we should make it easy for them to extend the platform by providing guidance / best practices on which layers to extend for common patterns of extension needs[ar][as][at].
Guardrails


An essential concern with supporting extensions is ensuring they do not have unintended consequences, e.g. performance degradation due to large size of data extension, race condition + colliding changes to the same data from multiple code extensions, or a bug in a code extension that brings down the whole production system.


Automated and process guardrails must be designed / put in place throughout the entire software lifecycle (e.g. design review + testing + production monitoring) to guard against unintended adverse consequences[au][av].
Lifecycle


The teams that build the extension are responsible for the extensions’ entire lifecycle[aw][ax][ay][az][ba][bb][bc][bd][be]. They own the extensions, and therefore they need to maintain them, manage their releases / deployment, be oncall for them, and manage their deprecation if/when the extension is no longer supported.
Co-Development


The doc so far has covered scenarios where we define clear boundaries where other teams build on one side, and Orders teams build on the other.


This leaves the elephant in the room - the topic of co-development (of which the controversial go/unblock is an example model).


On the one hand, it is easy to see why go/unblock is such a powerful tool for achieving key business objectives. The practical reality is, there will always be situations where an urgent / important business need cannot be staffed by the team who owns the code. No matter how much we invest in better planning, there will always be changes in the business environment that are outside of our control, and projects that take longer than expected since assessing the level of work is still a far-from-exact science.


On the other hand, it is also not surprising that go/unblock has resulted in some pain and frustration, e.g.


* It takes a lot of time and effort to bring someone up to speed.[bf] For a new engineer joining the team, that investment pays off over time as they become a valuable contributor for years to come. For someone doing an unblock, however, they only work on the immediate task at hand and then move on. It is thus relatively expensive, not to mention draining to train people and see them leave.


* Incentives are not necessarily well-aligned. The people working on the unblock are primarily incentivized to complete the task at hand[bg][bh], whereas the team who owns the code has longer-term incentives. It also creates a “build-and-run” situation where the team that owns it has to maintain / be oncall for code that someone else developed.


* Team Identity matters - there are many, many ways to build a given functionality, with numerous nuanced tradeoffs. What enables teams to be able to move forward (when there are so many ways to be misaligned) is an implicit social contract to develop a common way of doing things. Having someone from another team who is bound by a different social contract could be quite disruptive to the dynamics.


It is easy to see why there are strong proponents and opponents of go/unblock.


Sometimes, our opposition to go/unblock has been perceived as not believing in the capabilities of engineers from other teams. I do not find this line of thinking to be helpful, and distract us from discussing the inherent challenges of co-development across team boundaries.


Given that we are inevitably going to find ourselves in situations where there are urgent / important work that needs to be done but we cannot immediately take on, I believe it is essential that we experiment with co-development operating models to learn what would work best. For example, we could:


* Instead of a transactional, project-based approach, have teams work together on a longer-term shared mission, such as Orders migration, to make the upfront investment in bringing people up-to-speed more worthwhile.




* In that same vein, I believe that other teams will have long-term, ongoing needs to modify the Orders code base[bi]. Therefore, a variation is to ask that teams who want to work in Orders code bases to have dedicated engineers with Orders expertise[bj][bk][bl][bm].


* With the longer-term collaboration, we can also invest in aligning the team culture and how we work, as well as share the maintenance responsibilities. For example, we should explore how to share the oncall responsibilities[bn][bo].


[a]One underlying thing we don't mention explicitly is the role that speed of experimentation plays. Some of the patterns we have today are born out of the perception that everything takes a long time and that we must build the full functionality to learn. What is the role of spikes, small experiments to learn more about the constraints/ice-burgs that cause us to be more conservative? Is is possible to speed up that early discovery?
[b]That is a really interesting point. I'd love to hear feedback from the team on this.
[c]Good point Oseyi - I think investing in the ability to iterate quickly and safely would pay dividends. From what I've observed, we're afraid to get things wrong because, since we own a public API, we have to maintain it "forever". This leads to longer decision making cycles - but to be transparent, I'm not convinced that the end result is notably better.
[d]+1 on all of this, and to further add: I think our culture of divvying up work in a stack ranked list and drawing a line based on eng capacity doesn't implicitly feel like it allows for much experimentation - in fact, it feels like the quarter has been planned out with very specific pre-determined work (which itself was derived from an even larger list of pre-determined work - the annual plan) and job becomes executing on that with little sense of wiggle room. I've not seen many teams at square find a way to break this mold in an effective way that doesn't just come at the direct cost of delivering against funded objectives.


What can we do to create space for true experimentation and faster learning?
[e]@jguinta@squareup.com - I think we should publish the "final API" to the public, but to know what the final API should look like, we need to experiment and learn (in private).


I have not gotten the sense that we have been doing that. It seems that while we have alpha / beta and so on, how we operate has been to treat each change as if it is final.
[f]@joellevin@squareup.com could you tell me more? I am not sure that stack ranking and drawing lines have to inherently prevent experimentation, but can believe that it does in practice.


For example, if we are stack ranking "results we want to achieve", then it'd seem that, theoretically, it leaves a lot of space for experimentation on how to achieve that result.
[g]I agree with the above that the current AP and quarter planning process seems too rigid. Often other teams are taking dependencies on expected outcomes based on what we are publishing and trying to experiment presents a real risk that is hard to want to take on. Most places I have been at run more agile with top level OKRs and plans towards specific themes and goals that might change over time. The idea is that all teams should be working towards the most valuable work streams for the company and those might change quarter to quarter. In those situations they tend to want to "fail fast" and as long as teams are in constant communication with each other and failure is not viewed in a negative light things usually work smoothly. I also think we spend lots of time into actually planning and replanning that we could be taking to do experimentation within a team. Its expensive to size/plan/sequence and then need to do that repeatedly throughout the year (both to leads and to the teams).


I also agree with @jguinta@squareup.com that getting the API shape correct is often a "requirement" even in the case of "private". My experience is that if an outside team takes a dependency on what you are building they become uninterested in needing to shift to something new later (usually coined a "migration"). Even with an "private" API I think we would end up needing to be explicit that we were not 100% sure this is going to be the final thing (and I am not sure where our API WG or other processes here at Square draw the line about needing to support things in the future).
[h]+1 to the sentiment that we should be comfortable testing API shapes and functionality in private and should set the expectations both internally and externally that this shape may not be final and is subject to changes based on the outcomes of our experiments.
[i]_Marked as resolved_
[j]_Re-opened_
[k]@oseyi@squareup.com agree that we need agreement from the clients of the API to iterate with us.
[l]Thank you!
[m]@stevec@squareup.com do you see *time* playing a role here? For example, RST and RTL do not own their own backend systems and today sidecar all of their data into the bill. It might not be the best approach long term, but it would be almost trivial for us to offer Custom Attributes or private fields in the Order to plug data modeling gaps in the short term and acknowledge that there may be a migration cost in the longer term.
[n]You point out an importance nuance.


I think there are some principles that are independent of time. For example, what @wren@squareup.com stated about if the platform has to understand it, then it should not be an extension, is an example of something that would be time-independent.


But if they sidecar data that can be opaque to Orders today, but maybe some time later we may add functionalities that might want to use that data? To me that is fine.


IOW, I do not see what we are doing as having one shot to build the perfect Orders system. The business needs will change, we will learn things, and what is private today may benefit from being not private any more, that is the desirable outcome.


Finally, I think there is also a subtle part about whose decision it should be. I think it is up to us to decide that we will not have our code be dependent on their data, but whether they want to use our fields vs. private fields should probably be their decision, based on whether our fields offer the value they are looking for.
[o]The principle sent down from MOC was essentially "it gets modeled in the platform if the _platform_ needs to understand it". Naturally this still isn't a perfect filter, but it suggests that, even if two verticals want to agree to share data, that can be done in extensions rather than the core.


You hint at the future problem of "elevating" custom data into the core platform, but I think the current strategy is to cross that bridge when we get there.
[p]+1 to "cross that bridge when we get there".
[q]I understand the sentiment, but we really are signing ourselves up for a load of pain when we get to that bridge. I continue to read about 3P devs wanting access to e.g. RST table data - exposing that via CAs will be a nightmare. But if we have air cover for that situation, then punting sounds reasonable.
[r]I definitely do not want to minimize the challenge we will face at that point. That said, I do think that fundamentally, getting all new 1P transactions to be Orders and enabling 3P devs to access RST tables are not the same goals. Trying to solve for too many goals / constraints at the same time is a path to paralysis; we need to prioritize the goals and sequence them. Deferring to solve a challenging problem later so that we can focus on solving the current challenging problem is sometimes necessary.
[s]To add to this I think we should be clear that whatever future "elevating" we do would be a value add that teams would be responsible for migrating to themselves. If that is the case we wouldn't "take away" what they did today (CA's for an example) and the expectation would be the team could continue on what they have or migrate to the new thing
[t]Yes, that sounds like the right expectation to set, though I would say that as the platform owner, we should have the incentive to make it easier for people to adopt our value adds.
[u]Agree that we should try (reasonably) to make it easier for people to adopt - but not at the cost of slowing down forward momentum (at least imo). I don't want to see us stuck owning others migrations (and getting in the way again). Our role can/should be to provide a reasonable platform and offer consulting on how to migrate but not perform the actual migration - that being said there are strategic reasons for a case by case analysis of this. I just think we should be clear in the beginning that we are not "on the hook" by default to migrate someones custom solution
[v]Some principles here might be -- whether that data has a lifecycle outside the order's lifecycle, or merely describes something about an order contract ... whether other API entities need to be able to reference that data as an entity in its own right ... whether the data is complex enough that we can expect to need to version it / evolve its schema over time.
[w]We should also have principles for how in addition to the when. Building a primitive is hard, building one that relies on another primitive to house some data as a "foreign key" is even harder. Is it our job to make it easy?
[x]I don't know that it is our job to make it easier honestly- especially when said primitive is being built primarily because of the needs of the "team" building it. The Bookings API is a good example in my mind - but acknowledging that my feelings about that API might be very different from others.
[y]This also reminds me that there seems to be a class of problems, or JTBDs, that fundamentally involve seams across multiple primitives, that organizationally do not seem to belong to anyone. Two-phase commit (to make transactional changes across multiple primitives) comes up as a recent example. 
 
It is outside the scope of this doc, but seems worthwhile to discuss separately on how to bring about a good outcome for Square and sellers.
[z]@stevec@squareup.com 2pc was one of the examples I was thinking of. If we're telling other teams "No, you have to use this new pattern and that comes with X problem patterns", I wonder if it falls on us to help solve for X. But, agree it is likely outside of the scope of this doc.
[aa]Just noting I would like to involved in this future conversation as well. Most places handle this kind of thing through reference architectures or RFC type processes for scaling "how to build" out to the company
[ab]Another alternative to this is a company (or at least BU) wide data lake where all data must be shipped to. This allows consumers to do what they want with the data outside of our specific system. This will not solve for every use case but I think would represent a large majority of them
[ac]Worth pointing out that the orders API doesn't _do_ anything! It records the actions of other systems, and passes judgement upon them when they ask us whether they _should_ do something. This is an important distinction, because it allows those external actors to choose what they want to do, when they want to do it ... and we just make sure that what they're about to do isn't going to break some fundamental constraint of the order.


So I might reinterpret your observation here to speak about changing the definitions of "what will break an order" -- instead of "doing A followed by B" we "permit B to occur only after A", or similar. We have various flavors of orders (historically called workflows) that apply different sorts of rules -- some that allow fulfillment only after payment, others that don't care, etc -- and we should turn that canned set of flavors into a part of the platform you can customize yourself.


Actually exposing "high level actions" or "custom logic you can associate with an order" might be more in line with your original intent here -- it's just not something Orders has started experimenting with yet. You might imagine associating a well-known action name with an order, that can have different implementations plugged into it (think virtual functions), and those implementations pull levers on various Square APIs to achieve some high-level goal that was envisioned by the order creator / a specific vertical / etc. This is the space that Maestro is intended to explore, but up to this point it has been a solution waiting for the problems to be presented to us.
[ad]one real scenario is the conflict detection/resolution aspect of Open Tickets. is the conflict detection code something that could be isolated into a "policy" unit that would enable others to "define/design/implement their own policy"?
[ae]The open tickets conflict resolution model is inherently in conflict with orders "single source of truth" model. I view it as a separate entry path with defined conflict resolution mechanisms that dictate how a proposed edit will be merged with the "truth" stored in the orders server. How we organize this in the codebase (is it part of the core API, a separate system that's subservient to orders-api) isn't yet clear to me.
[af]Another interesting example I see at companies like ours is when to release an order for fulfillment. This relies a lot on payment states and risks and typically modeled as "releasing rules" in some sort of DSL (or something similar to that)
[ag]Another approach that may sidestep this is to rely on events and code written in other teams' systems to provide the extensibility. If your use case can be (safely) made asynchronous, this model neatly compartmentalizes the complexity. Synchronous use cases, or those which seem to require "locking the order", are a different matter, and likely require a much more delicate solution.
[ah]+1 to relying on events; also curious about a list of use cases where we could get by with an asynchronous model vs. not.
[ai]I am heavily in favor of using events to solve these problems and have seen this used at scale at multiple prior places in different verticals. Taking an event based approach allows various parts of the system to react to things and moves the decision power away from any one group / team.
[aj]Who would gather the list of use cases? This seems like something the vertical teams would be best placed to explain
[ak]We know of at least one major use case (which might be enough honestly) - multiple employee attribution on a sale.
[al]@mlummus@squareup.com and @macchiarelli@squareup.com have been putting together the full list of remaining needs to complete the migration.


The next step is to plan for completing that list, using the extensibility framework as a key strategy.
[am]In really bad cases multiple "extensions" are modifying the same data for different use cases and can cause weird contention issues in the system (including race conditions and/or not knowing who the modifier of the data was and not being able to easily trace this back). It is very important to setup boundaries for how data manipulation will work in these cases (if that is desired)
[an]A really good point. Let me add it below to the Guardrails section
[ao]💯
[ap]I agree with this but it will require a bit of shift from how we operate today IMO. We need to start thinking about building these "building blocks" outside of just developing for the "current business need" or migration effort. Often we are focused on building the easiest thing for the customer to solve the problem as stated (one API) and we need to start thinking about exposing the solutions at a lower layers that can be combined to solve the same problem and future problems we might not even know about (multiple base APIs utilized together).
[aq]+1
[ar]+1 to this too. IMO a key part of why this is hard is that each request for extension requires fresh analysis and evaluation. If we had a "menu" of approved extension patterns, then it lowers the barrier to entry (including for ramp up/onboarding).
[as]+100. Principles, principles, principles!
[at]agree with reference patterns and principles because I don't think "request for extension requires fresh analysis and evaluation" will be scalable in the short term
[au]I think we also need to consider putting software limits around extensions as part of the base requirements (at a minimum rate limits and/or requiring certain metrics and alerts/automated actions) be in place. I don't want to rely on only human processes to guard against this.
[av]That was my intention as well. Clarified.
[aw]This sounds good in theory but in practice things are not always this straightforward. When there is a production incident in an extension in an existing system people are going to look the hosting system to figure out the problem. Not saying this isn't "workable" just mentioning this won't be "free" and will likely require a bit more definition around how we deal with production issues, etc.
[ax]This is, of course, the real criticism against go/unblock -- once the code is in somebody else's codebase, the codebase owner is almost always going to bear the support costs. Even if there is an agreement to the contrary, identifying the problem, making the case that the "unblocker" should allocate resources to fixing it, bearing the operational pain until such a fix is in place ... all of these will fall on the codebase owner.


Avoiding these costs requires us to build for multi-tenancy in the first place, and compartmentalize the extension points so that they don't cause harm to the platform as a whole. Essentially, extensions -- done right -- should be built _on_ the platform, but not _in_ the platform.
[ay]I agree. The team owning the hosting system will always bear some cost. It will not be free, but I believe the ROI to be worthwhile, if we do the  compartmentalization, streamlined debugging to identify the offending extension, etc.


What I am asking for is a row in AP 2022, that specifies what it will take for us to make this happen.
[az]>What I am asking for is a row in AP 2022, that specifies what it will take for us to make this happen.
What specifically are you asking for us to have in an AP 22 item? Supporting extensions? Would this just become part of KLO costs? The problem with representing KLO (and/or extensions) in an AP is it is largely unknown and impacted by changes/other teams plans as well. We can guess based on historical values (what we do for KLO today) but we wouldn't have that data in year one for extensions
[ba]Thanks for the clarifying questions!


1. I don't see it as KLO, but rather new functionalities that we need to invest in. To the points from earlier in the thread, the level of compartmentalization needs to be designed / implemented.


Maestro is a concrete example of extensibility project that is not KLO.


2. You are right that estimates are going to be quite imprecise at the moment. I'd like to suggest a two-phase approach:


a. put a row down with a high-level guess; this will enable us to have conversations with other teams to also put line items down in their AP to build extensions


b. as we discussed, we are gathering a set of engineers together to go through the list of remaining work, to strategize how best to get them done. That will refine our understanding of the extensibility needs, and I'd like us to refine the estimate from a) above accordingly.
[bb]cc: @aszerlip@squareup.com / @skhan@squareup.com looks like we are asking to add this to 22 AP
[bc]Also, I think it is quite reasonable, based on comments in this doc, to consider events as an extensibility project.
[bd]We will account for 1) maestro and 2) events at a minimum as part of this extensibility. Do you have a sense for what % of Orders investment in 2022 should be on extensibility? In other words, how will we know if we are investing too much or not enough?
[be]Thanks Aaron. My goal is not to reach a % of investment, but to complete the migration.


So, working backwards from that, we have the list of data / functionality gaps, we are gathering a set of engineers across teams to identify extensibility options (including custom attributes, events, and others) to complete the work, scope them, and then place the request for staffing those options in AP.
[bf]A lot of teams are standing up "orders squads" so I'm curious if this problem goes away in the medium term once we allow these squads to ramp up with us so they can contribute on an ongoing basis.
[bg]To push this further, the team asking for the unblock is interested completing the task at hand in a way that serves their needs but is not always able to see the full picture or understand what similar functionality other teams may need. Platform teams tend to want to build platform capabilities that improve the platform as a whole (which I think is almost always the right way to perceive any new work) instead of bespoke one-off solutions that only help one customer, which in turn often makes this incentive gap conversation even harder to have and increases the scope of the work.
[bh]What you are describing generally matches my experience as well (having been on both platform and product teams).


To me, one of the goals of extensions is to enable teams to completing their task in a way just for their needs.


OTOH, if what they need to accomplish does need to be in the "platform code" itself, then I do think they should follow the same principles / rituals that the platform team applies in their own development.
[bi]I think it's important to define what sorts of "need to modify" we expect other teams to have, and that we're willing to support. Ultimately, we are responsible for the health of this system, and the closer to the core of that system we allow external parties to work, the more likely we are to negatively impact the system's overall health. That's not because engineers outside our organization are worse at the job, it's because they lack the context they'd have if they worked in this codebase day-in and day-out.


I would argue that, each time an external team asks to modify our code base in a way that can't use an existing extension point, we need to take a good hard look to see if there's some new extension point that we should be building to re-direct that need in the future. In fact, re-imagining our system in terms of a layered-stack of extension points will make our own internal development easier to reason about and less prone to errors.
[bj]See my comment above but a bunch of teams are already doing this so far RTL, RST and soon APPT (per my conversations with Willem this week)
[bk]This is certainly an indication that they will be receptive to this, though my sense is that there is no well established path for them to come up to speed, nor is there an established channel for them to work with us or each other, and establishing principles on how they/we work, so there is room to make this work much better.
[bl]Not saying this can't work but it make me have a lot of questions. Is this going to be scalable long term? That would mean each team has to have someone who is actively keeping up with orders projects and changes. What if that person leaves the team? In this example how are other teams keeping up with what is going on in orders and how it impacts them? Does this add a burden to our teams to help train new people on other teams?
[bm]All great questions!


I expect the client teams to be responsible for ensuring that they continue to have expertise in the team, as long as they continue to need to do work with the platform.


As an analogy, at a previous job, we were running a forked version of mysql (long story), so we definitely staffed a team of people who are familiar with the mysql codebase.


As for how people keep up with orders, I agree we need to invest and be thoughtful about that. I would say that investment is valuable for our own team as well, as the team continues to grow/scale.
[bn]I think we've generally found that a small group of highly knowledgeable oncall engineers is much better at keeping the system healthy than a larger pool of less trained ones (e.g. because they're trained to be oncall for a larger number of systems).
[bo]Yes, I am looking for a balance in navigating the polarity between


1. keeping the group small to maximize system health
2. aligning incentives between # of people contributing to the code and the maintenance responsibilities for them


Note that we face this no matter which team the people are from. The amount of work is such that we necessarily need a larger # of people to be involved.